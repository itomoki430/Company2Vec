{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"./src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch\n",
    "import logging\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "import  matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "from io import open\n",
    "\n",
    "import gzip\n",
    "logger = logging.getLogger(__name__)\n",
    "import  matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from torch import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import glob\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import requests\n",
    "import copy\n",
    "import ml_metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_en import *\n",
    "from evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return_val_dict.pkl  stock_price.csv  text_data_id.csv  ticker_list.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_val_dict = pickle.load(open(\"data/return_val_dict.pkl\", \"rb\"))\n",
    "df_ticker = pd.read_csv(\"data/ticker_list.csv\")\n",
    "text_data_id_df = pd.read_csv(\"data/text_data_id.csv\")\n",
    "month_stock_info_df = pd.read_csv(\"data/stock_price.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker2sector = dict(zip(df_ticker[\"ticker\"], df_ticker[\"sector\"]))\n",
    "ticker2industry = dict(zip(df_ticker[\"ticker\"], df_ticker[\"industry\"]))\n",
    "all_month_list = np.sort(list(set(month_stock_info_df[\"month\"])))\n",
    "month2index = dict(zip(all_month_list, range(len(all_month_list))))\n",
    "text_data = dict(zip(text_data_id_df[\"ticker\"], [\n",
    "    [np.array(text_data_id_df[\"text_id\"].iloc[i][1:-1].split(\",\")).astype(np.int32)] for i in range(len(text_data_id_df))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_stock_price_list = []\n",
    "sector_array = []\n",
    "industry_array = []\n",
    "use_text_data = []\n",
    "use_ticker_list_data = []\n",
    "stock_size = 59\n",
    "for index, ticker in enumerate(df_ticker[\"ticker\"]):\n",
    "    if ticker in return_val_dict:\n",
    "        if len(return_val_dict[ticker]) >= 12:\n",
    "            if  (type(ticker2sector[ticker]) == str) :\n",
    "                use_stock_price_list.append(return_val_dict[ticker][-stock_size:])\n",
    "                sector_array.append(ticker2sector[ticker])\n",
    "                use_text_data.append(text_data[ticker])\n",
    "                industry_array.append(ticker2industry[ticker])\n",
    "                use_ticker_list_data.append(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2462"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_ticker[\"ticker\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_similarity_mat_df = pd.read_csv(\"./stock_similarity_mat/common_length_mat.csv\",  index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_ticker_list = np.sort(df_ticker[\"ticker\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_mat_df = pd.read_csv(\"./stock_similarity_mat/all_similarity_mat.csv\", \n",
    "                                index_col=0)\n",
    "similarity_mat_df = similarity_mat_df[df_ticker[\"ticker\"]].T[df_ticker[\"ticker\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_inner_mat = np.array(similarity_mat_df[\n",
    "    [len(return_val_dict[ticker]) > 12 for index, ticker in enumerate(df_ticker[\"ticker\"])]].T[\n",
    "    [len(return_val_dict[ticker]) > 12 for index, ticker in enumerate(df_ticker[\"ticker\"])]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector2id = dict(zip(np.sort(list(set(sector_array))), range(len(set(sector_array)))))\n",
    "industry2id = dict(zip(np.sort(list(set(industry_array))), range(len(set(industry_array)))))\n",
    "use_label_data = [sector2id[sector] for sector in sector_array]\n",
    "use_industry_data = [industry2id[sector] for sector in industry_array]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Using Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "gradient_accumulation_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_size = 1800\n",
    "valid_data_size = 262\n",
    "test_data_size = (len(use_label_data) - (train_data_size + valid_data_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x = use_text_data[0:train_data_size]\n",
    "train_data_y = use_label_data[0:train_data_size]\n",
    "train_data_industry = use_industry_data[0:train_data_size]\n",
    "train_inner_stock_mat = similarity_inner_mat[:train_data_size, :train_data_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data_x = use_text_data[train_data_size:train_data_size + valid_data_size]\n",
    "valid_data_y = use_label_data[train_data_size:train_data_size + valid_data_size]\n",
    "valid_data_industry = use_industry_data[train_data_size:train_data_size + valid_data_size]\n",
    "valid_inner_stock_mat = similarity_inner_mat[train_data_size:train_data_size + valid_data_size, \n",
    "                                                                                  train_data_size:train_data_size + valid_data_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_x = use_text_data[-test_data_size:]\n",
    "test_data_y = use_label_data[-test_data_size:]\n",
    "test_data_industry = use_industry_data[-test_data_size:]\n",
    "test_inner_stock_mat = similarity_inner_mat[-test_data_size:, -test_data_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stock_label_y = np.array(use_stock_price_list)[0:train_data_size]\n",
    "valid_label_y = np.array(use_stock_price_list)[train_data_size:train_data_size + valid_data_size]\n",
    "test_stock_label_y = np.array(use_stock_price_list)[-test_data_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_size =    1\n",
    "total_train_examples = len(train_data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_num = max(use_label_data)+ 1\n",
    "industry_num = max(use_industry_data)+ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceMeanVec(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pooler_dev): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       "  (pooler_stock): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       "  (att): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (att_industry): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
       "  (classifier_industry): Linear(in_features=768, out_features=208, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_config = BertConfig.from_pretrained('models/PreTrainigNLMbyBert/finetuned_lm/')\n",
    "model_state_dict = torch.load(\"models/PreTrainigNLMbyBert/finetuned_lm/pytorch_model.bin\")\n",
    "model = BertForSequenceMeanVec(bert_config, label_num, industry_num, state_dict=model_state_dict)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available()  else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "        #{'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         #'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "num_train_optimization_steps = int(\n",
    "        total_train_examples / batch_size / gradient_accumulation_steps)\n",
    "warmup_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpu = 2\n",
    "model.to(device)\n",
    "if -1 != -1:\n",
    "    try:\n",
    "        from apex.parallel import DistributedDataParallel as DDP\n",
    "    except ImportError:\n",
    "        raise ImportError(\n",
    "            \"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
    "    model = DDP(model)\n",
    "elif n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters)\n",
    "scheduler = WarmupLinearSchedule(optimizer, warmup_steps=warmup_steps,\n",
    "                                     t_total=num_train_optimization_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_size =   1\n",
    "batch_size = 8\n",
    "test_data_size = len(test_data_y)\n",
    "max_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock2stock_similarity_mat = copy.deepcopy(train_inner_stock_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_value = (stock2stock_similarity_mat[stock2stock_similarity_mat < 0.9999].mean() + \n",
    "stock2stock_similarity_mat[stock2stock_similarity_mat < 0.9999].std() * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fct = CrossEntropyLoss(ignore_index = -1)\n",
    "loss_mse = MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sector\n",
      "same:  0.75584406\n",
      "other:  0.7359424\n",
      "industry\n",
      "same:  0.75041085\n",
      "other:  0.7386292\n"
     ]
    }
   ],
   "source": [
    "sentence_representation_all = evaluate_model_with_cosine_similarity(\n",
    "    model, test_data_x, test_data_y, test_data_industry, test_data_size, \n",
    "    batch_size =  batch_size, max_seq_length = max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sector\n",
      "1 : 0.455\n",
      "5 : 0.3965\n",
      "10 : 0.36825\n",
      "industry\n",
      "1 : 0.1575\n",
      "5 : 0.111\n",
      "10 : 0.08925\n"
     ]
    }
   ],
   "source": [
    "doc2soc_similarity_mat = sklearn.metrics.pairwise.cosine_similarity(sentence_representation_all)\n",
    "sort_values = np.argsort(doc2soc_similarity_mat, axis = 1)[:,-1::-1]\n",
    "    \n",
    "print (\"sector\")\n",
    "for top_n in [1,5,10]:\n",
    "    print (top_n , \":\", np.array([np.array(test_data_y)[sort_values[index]][1:top_n+1 ] ==  test_data_y[index] \n",
    "                for index in range(len(test_data_y))]).mean())\n",
    "\n",
    "print (\"industry\")\n",
    "for top_n in [1,5,10]:\n",
    "    print (top_n , \":\", np.array([np.array(test_data_industry)[sort_values[index]][1:top_n+1 ] ==  test_data_industry[index] \n",
    "    for index in range(len(test_data_industry))]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "mask_volume = 1\n",
    "\n",
    "#train_data_y_mask = np.array(copy.deepcopy(train_data_y))\n",
    "#train_data_y_mask[:int(len(train_data_y_mask) * mask_volume)] = -1\n",
    "#train_data_industry_mask = np.array(train_data_industry)\n",
    "#train_data_industry_mask[:int(len(train_data_y_mask) * mask_volume)] = -1\n",
    "\n",
    "\n",
    "seed_num = 0\n",
    "train_data_y_mask = np.array(copy.deepcopy(train_data_y))\n",
    "#train_data_y_mask[(train_data_y_mask % 2) != 0] = -1\n",
    "# train_data_y_mask[(train_data_y_mask % 5) != 0] = -1\n",
    "train_data_y_mask[(train_data_y_mask) == 0] = -1\n",
    "train_data_industry_mask = np.array(train_data_industry)\n",
    "#train_data_industry_mask[(train_data_y_mask % 2) != 0] = -1\n",
    "# train_data_y_mask[(train_data_y_mask % 5) != 0] = -1\n",
    "train_data_industry_mask[(train_data_y_mask) == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2sector = dict(zip(range(len(set(sector_array))), np.sort(list(set(sector_array)))))\n",
    "id2industry = dict(zip(range(len(set(industry_array))), np.sort(list(set(industry_array)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test_data_industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[np.mean(np.array(test_data_industry) == industry2id[word]) for word, theme_vector_gpu in zip(theme_word_list, pooled_output)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_count_dict  = np.array(test_data_industry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_actual_predicted_list(sentence_representation_all, theme_word_list, pooled_output, th_val = 0):\n",
    "    actual_list = []\n",
    "    predicted_list = []\n",
    "    for word, theme_vector_gpu in zip(theme_word_list, pooled_output):\n",
    "        theme_vector = theme_vector_gpu.detach().to(\"cpu\").numpy()\n",
    "        if np.mean(np.array(test_data_industry) == industry2id[word])  <= th_val:\n",
    "            continue\n",
    "        #print (word)\n",
    "        doc2theme_similarity_mat = sklearn.metrics.pairwise.cosine_similarity(sentence_representation_all, theme_vector.reshape(1, -1))\n",
    "        actual = np.array(range(len(test_data_industry)))[np.array(test_data_industry) == industry2id[word]]\n",
    "        predicted = np.argsort(doc2theme_similarity_mat[:,0])[-1::-1]\n",
    "        actual_list.append(list(actual))\n",
    "        predicted_list.append(list(predicted))\n",
    "    return actual_list, predicted_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_word_list = [word for word in industry2id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_token_list = []\n",
    "for word in theme_word_list:\n",
    "    text = \"[CLS] \" + word +  \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    tokenized_id = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    theme_token_list.append(tokenized_id)\n",
    "\n",
    "max_seq_length_company = 8\n",
    "input_ids_list = []\n",
    "for tokenized_id in theme_token_list:\n",
    "    input_array = np.zeros(max_seq_length_company, dtype=np.int)\n",
    "    input_array[:min(max_seq_length_company, len(tokenized_id))] = tokenized_id[:min(max_seq_length_company, len(tokenized_id))]\n",
    "    input_ids_list.append(input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_token_list = []\n",
    "for sector_id in np.sort(list(set(train_data_y_mask)))[1:]:\n",
    "    text = \"[CLS] \" + id2sector[sector_id] +  \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    tokenized_id = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    sector_token_list.append(tokenized_id)\n",
    "\n",
    "max_seq_length_company = 8\n",
    "input_sector_ids_list = []\n",
    "for tokenized_id in sector_token_list:\n",
    "    input_array = np.zeros(max_seq_length_company, dtype=np.int)\n",
    "    input_array[:min(max_seq_length_company, len(tokenized_id))] = tokenized_id[:min(max_seq_length_company, len(tokenized_id))]\n",
    "    input_sector_ids_list.append(input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = nn.CosineSimilarity(dim=2, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceMeanVec(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pooler_dev): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       "  (pooler_stock): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       "  (att): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (att_industry): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
       "  (classifier_industry): Linear(in_features=768, out_features=208, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.module.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file_name = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(max_epoch, write_file_name, use_loss_sector = True, use_loss_stock = True, use_sector_nm_loss = True, use_loss_industry = False):\n",
    "    stock_loss_scale = 0\n",
    "    max_valid_f1_score = 0\n",
    "    for epoch in range(max_epoch):\n",
    "        tr_loss = 0\n",
    "        nb_tr_examples, nb_tr_steps = 0, 0\n",
    "        global_step = 0\n",
    "        first_time = time.time()\n",
    "        model.train()\n",
    "        random_perm = np.random.permutation(train_data_size)\n",
    "        train_data_x_rand = np.array(train_data_x[0:train_data_size])[random_perm]\n",
    "        train_data_y_rand = np.array(train_data_y_mask[:train_data_size])[random_perm]\n",
    "        train_data_y_rand_stock = np.array(train_stock_label_y[0:train_data_size])[random_perm]\n",
    "        train_data_y_rand_industry = np.array(train_data_industry_mask[0:train_data_size])[random_perm]\n",
    "        stock_similarity_random = train_inner_stock_mat[random_perm].T[random_perm]\n",
    "        #for data_index, (doc, label) in enumerate(zip(train_data_x_rand, train_data_y_rand)):\n",
    "        for data_index in range(0, len(train_data_x_rand), batch_size):\n",
    "            loss = 0\n",
    "            data_batch = train_data_x_rand[data_index:data_index+batch_size]\n",
    "            doc_batch = [doc[0] for doc in data_batch]\n",
    "            #if  len(doc) == 0:\n",
    "                #continue\n",
    "            #print ((time.time()-first_time), (\", \"),  (data_index))\n",
    "            logits = 0\n",
    "            stock_logits = 0\n",
    "            #for doc_index in range(0, min(len(doc), sentence_size), batch_size):\n",
    "            label_batch = np.array(train_data_y_rand[data_index:data_index+batch_size])\n",
    "            #label_batch_stock = train_data_y_rand_stock[data_index:data_index+batch_size]\n",
    "            label_batch_industry = train_data_y_rand_industry[data_index:data_index+batch_size]\n",
    "            input_array_doc = []\n",
    "            for doc_batch_index, input_ids in enumerate(doc_batch):\n",
    "                    input_array = np.zeros(max_seq_length, dtype=np.int)\n",
    "                    input_array[:min(max_seq_length, len(input_ids))] = input_ids[:min(max_seq_length, len(input_ids))]\n",
    "                    input_array_doc.append(input_array)\n",
    "            input_ids = torch.LongTensor(np.array(input_array_doc).astype(np.int32))\n",
    "            label_logits, pooled_output, industry_logits = model(input_ids, \n",
    "                                                                                       labels= torch.LongTensor(label_batch), \n",
    "                                                                                       label_industry = label_batch_industry,                                                   \n",
    "                                                                                       stock_vol = 0)\n",
    "\n",
    "\n",
    "            logits  = label_logits\n",
    "            industry_logits = industry_logits\n",
    "            stock_similarity = torch.Tensor(stock_similarity_random[data_index:data_index+batch_size, data_index:data_index+batch_size])\n",
    "            sector_similarity = torch.Tensor(np.array(train_data_y_rand[data_index:data_index+batch_size][:,np.newaxis])\n",
    "                                                       == np.array(train_data_y_rand[data_index:data_index+batch_size][np.newaxis, :]))\n",
    "\n",
    "            pooled_output_norm = (pooled_output.T/F.norm(pooled_output, dim = 1)).T\n",
    "            doc2doc_similarity =  torch.matmul(pooled_output_norm, pooled_output_norm.T)\n",
    "            loss_stock = loss_mse(doc2doc_similarity[stock_similarity != 0],  stock_similarity[stock_similarity != 0].to(\"cuda\"))\n",
    "            loss_sector = loss_fct(logits,  torch.LongTensor(np.array(train_data_y_rand[data_index:data_index+batch_size])).to(\"cuda\"))\n",
    "            loss_industry = loss_fct(industry_logits, torch.LongTensor(np.array(train_data_y_rand_industry[data_index:data_index+batch_size])).to(\"cuda\"))\n",
    "\n",
    "            #loss = outputs[0].mean()\n",
    "            tr_loss += loss_sector.detach().to(\"cpu\").item()\n",
    "            \n",
    "            if use_loss_sector:\n",
    "                loss += loss_sector /(32/batch_size)\n",
    "            if use_loss_industry:\n",
    "                loss += loss_industry/(32/batch_size)\n",
    "            if use_loss_stock:\n",
    "                loss += loss_stock/(32/batch_size)\n",
    "            \n",
    "            \n",
    "            if use_sector_nm_loss:\n",
    "                if ((((data_index + batch_size) % 32) == 0) or (data_index == (len(train_data_x_rand)-1))):\n",
    "                    input_ids = torch.LongTensor(np.array(input_sector_ids_list).astype(np.int32))\n",
    "                    label_sector_logits, pooled_sector_output = model(input_ids, labels= torch.LongTensor(np.sort(list(set(train_data_y_mask)))[1:]),  \n",
    "                                                            label_industry = None,\n",
    "                                                            labels_stock =  None, stock_vol = 0)\n",
    "\n",
    "                    loss_regularize = loss_fct(label_sector_logits,  torch.LongTensor(np.array(np.sort(list(set(train_data_y_mask)))[1:])).to(\"cuda\"))\n",
    "                    loss += 0.1 * loss_regularize\n",
    "                    \n",
    "            loss.backward()\n",
    "            if ((((data_index + batch_size) % 32) == 0) or (data_index == (len(train_data_x_rand)-1))):\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                global_step += 1\n",
    "\n",
    "\n",
    "        pred_label_valid, answer_label_valid, pred_industry_valid, answer_indesutry_valid, tr_loss_valid = evaluate_model(\n",
    "        model, valid_data_x, valid_data_y, valid_data_industry, valid_data_size)\n",
    "        valid_f1_score = sklearn.metrics.f1_score(answer_label_valid, pred_label_valid, average = \"macro\")\n",
    "        if valid_f1_score >= max_valid_f1_score:\n",
    "            print (\"epoch\" + str(epoch ) +\": \" + str(tr_loss_valid/valid_data_size), valid_f1_score, \" time:\", str(time.time()-first_time))\n",
    "            max_valid_f1_score = valid_f1_score\n",
    "            model.module.to(\"cpu\").save_pretrained(write_file_name)\n",
    "            model.module.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0: 0.32226130434574973 0.21278984441848328  time: 91.81227731704712\n",
      "epoch3: 0.35246708602395677 0.21288459410525137  time: 282.90406680107117\n",
      "epoch4: 0.35190293079114143 0.2607106336311703  time: 291.11462235450745\n"
     ]
    }
   ],
   "source": [
    "train(max_epoch, write_file_name, use_loss_sector = True, use_loss_stock = True, use_sector_nm_loss = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
